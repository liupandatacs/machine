<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>
### 梯度下降推导






$$
J(\theta) =-\frac{1}{m}[\sum_{i=1}^ny^{(i)}log(h_{\theta}(x^{(i)}))+(1-y^{(i)})log(1-h_{\theta}(x^{(i)}))]
$$

其中：


$$
h_{\theta}(x^{(i)})=\frac{1}{1+e^{-\theta^{T}x}}
$$


设置：
$$
K(\theta)=y^{(i)}log(h_{\theta}(x^{(i)}))+(1-y^{(i)})log(1-h_{\theta}(x^{(i)}))
$$

$$
K(\theta)^{'}=y\frac{1}{h_{\theta}(x)}h_{\theta}(x)^{'}+(1-y)\frac{1}{1-h_{\theta}(x)}(1-h_{\theta}(x))^{'}
$$

$$
h(\theta)^{'}=h_{\theta}(x)(1-h_{\theta}(x))(\theta^Tx)^{'}
$$


$$
K(\theta)^{'}=y\frac{1}{h_{\theta}(x)}h_{\theta}(x)^{'}+(1-y)\frac{1}{1-h_{\theta}(x)}(1-h_{\theta}(x))^{'}=y(1-h_{\theta}(x))x+(y-1)h_{\theta}(x)x=(y-h_{\theta}(x))x
$$
因此
$$
J(\theta)^{'}=\frac{1}{m}[\sum_{i=1}^{n}（h_{(\theta)}(x)-y）x]
$$

$$
\frac{\partial J(\theta)^{'}}{\partial \theta_{j}}=\frac{1}{m}[\sum_{i=1}^{n}（h_{(\theta)}(x^{(i)})-y^{(i)}）x^{(i)}_j]
$$
